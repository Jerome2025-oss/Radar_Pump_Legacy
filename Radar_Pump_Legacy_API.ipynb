{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQ8pt_LwG9ad",
    "outputId": "b1e624aa-446b-4c1b-f3ea-2b86e8889ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "üì• Collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Fichier tokens introuvable ou illisible: /content/drive/MyDrive/tokens_perpetuels.txt ([Errno 2] No such file or directory: '/content/drive/MyDrive/tokens_perpetuels.txt')\n",
      "WARNING:__main__:Empty list of perpetual tokens: the report will be generated for ALL tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected parquet: /content/drive/MyDrive/crypto_data/crypto_data_wide_2025-W32.parquet -> exists=True\n",
      "üìä Generating report...\n",
      "‚úÖ Report updated: /content/drive/MyDrive/rapport_performance_crypto.xlsx\n",
      "‚è≥ Pausing for 10 minutes...\n"
     ]
    }
   ],
   "source": [
    "# Tout-en-un: installation, configuration, collecte, rapport (ex√©cuter cette cellule unique)\n",
    "!pip install -q pandas pyarrow requests openpyxl\n",
    "\n",
    "from google.colab import drive\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import logging\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import time\n",
    "from getpass import getpass\n",
    "\n",
    "# --- Logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- Mount Google Drive ---\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    logger.info(\"Google Drive mounted successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error mounting Google Drive: {e}. Please check your connection and authentication.\")\n",
    "\n",
    "# --- API CoinMarketCap ---\n",
    "try:\n",
    "    API_KEY = getpass(\"Entre ta cl√© API CoinMarketCap (masqu√©e): \")\n",
    "    if not API_KEY:\n",
    "        raise ValueError(\"Cl√© API vide.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Erreur saisie de la cl√© API: {e}\")\n",
    "\n",
    "try:\n",
    "    limit_input = input(\"Nombre de tokens √† analyser (ex: 2000): \").strip()\n",
    "    LIMIT = int(limit_input) if limit_input else 2000\n",
    "    if LIMIT <= 0:\n",
    "        raise ValueError\n",
    "except Exception:\n",
    "    LIMIT = 2000\n",
    "    print(\"Valeur invalide, utilisation de LIMIT=2000 par d√©faut.\")\n",
    "\n",
    "API_URL = f'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest?start=1&limit={LIMIT}&convert=USD'\n",
    "HEADERS = {\n",
    "    'X-CMC_PRO_API_KEY': API_KEY,\n",
    "    'Accept': 'application/json'\n",
    "}\n",
    "\n",
    "# --- Chemins Google Drive ---\n",
    "SAVE_DIR = \"/content/drive/MyDrive/crypto_data\"\n",
    "REPORT_FILE = \"/content/drive/MyDrive/rapport_performance_crypto.xlsx\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- Fonctions ---\n",
    "\n",
    "def get_weekly_parquet_filename():\n",
    "    now = datetime.datetime.now()\n",
    "    week_number = now.strftime(\"%G-W%V\")\n",
    "    return os.path.join(SAVE_DIR, f'crypto_data_wide_{week_number}.parquet')\n",
    "\n",
    "\n",
    "def get_current_crypto_data():\n",
    "    try:\n",
    "        if API_KEY in (None, \"\", \"REMPLACE_ICI_TA_CLE_API\"):\n",
    "            logger.error(\"API_KEY CoinMarketCap manquante: remplace API_KEY par ta cl√© r√©elle.\")\n",
    "            return None\n",
    "        response = requests.get(API_URL, headers=HEADERS, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        tokens = response.json().get('data', [])\n",
    "        timestamp_str = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "        data = [{\n",
    "            'ID': t.get('id'),\n",
    "            'Nom': t.get('name'),\n",
    "            'Symbole': t.get('symbol'),\n",
    "            'Prix (USD)': t['quote']['USD'].get('price'),\n",
    "            'Timestamp': timestamp_str\n",
    "        } for t in tokens]\n",
    "        df = pd.DataFrame(data)\n",
    "        df.sort_values(by='ID', inplace=True)\n",
    "        logger.info(f\"{len(df)} actifs re√ßus depuis CoinMarketCap.\")\n",
    "        return df\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Erreur API : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def collect_data():\n",
    "    CURRENT_PARQUET_FILE = get_weekly_parquet_filename()\n",
    "    BASE_DF = None\n",
    "    if os.path.exists(CURRENT_PARQUET_FILE):\n",
    "        try:\n",
    "            df_existing = pd.read_parquet(CURRENT_PARQUET_FILE)\n",
    "            BASE_DF = df_existing[['ID', 'Nom', 'Symbole']].drop_duplicates(subset=['ID']).sort_values('ID').reset_index(drop=True)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erreur lecture {CURRENT_PARQUET_FILE}: {e}\")\n",
    "\n",
    "    df_new_data = get_current_crypto_data()\n",
    "    if df_new_data is not None and not df_new_data.empty:\n",
    "        if BASE_DF is None:\n",
    "            BASE_DF = df_new_data[['ID', 'Nom', 'Symbole']].sort_values('ID').reset_index(drop=True)\n",
    "            df_to_save = df_new_data.pivot_table(index=['ID', 'Nom', 'Symbole'], columns='Timestamp', values='Prix (USD)').reset_index()\n",
    "            df_to_save.to_parquet(CURRENT_PARQUET_FILE)\n",
    "            logger.info(f\"Cr√©√©: {CURRENT_PARQUET_FILE}\")\n",
    "        else:\n",
    "            df_new_base = df_new_data[['ID', 'Nom', 'Symbole']].sort_values('ID').reset_index(drop=True)\n",
    "            df_merged_base = pd.merge(BASE_DF, df_new_base, on='ID', how='outer', suffixes=('', '_new'))\n",
    "            df_merged_base['Nom'] = df_merged_base['Nom'].fillna(df_merged_base['Nom_new'])\n",
    "            df_merged_base['Symbole'] = df_merged_base['Symbole'].fillna(df_merged_base['Symbole_new'])\n",
    "            df_merged_base.drop(columns=['Nom_new', 'Symbole_new'], inplace=True, errors='ignore')\n",
    "            df_merged_base.sort_values(by='ID', inplace=True)\n",
    "            BASE_DF = df_merged_base.reset_index(drop=True)\n",
    "\n",
    "            df_weekly_history = pd.read_parquet(CURRENT_PARQUET_FILE)\n",
    "            df_to_append = df_new_data.pivot_table(index=['ID'], columns='Timestamp', values='Prix (USD)').reset_index()\n",
    "            df_combined = pd.merge(df_weekly_history, df_to_append, on='ID', how='outer')\n",
    "            final_df = pd.merge(BASE_DF, df_combined.drop(columns=['Nom', 'Symbole'], errors='ignore'), on='ID', how='outer')\n",
    "            final_df.to_parquet(CURRENT_PARQUET_FILE)\n",
    "            logger.info(f\"Mise √† jour: {CURRENT_PARQUET_FILE} (colonnes={len(final_df.columns)})\")\n",
    "    return CURRENT_PARQUET_FILE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_performance_report(parquet_file: str, output_excel_file: str) -> bool:\n",
    "    if not os.path.exists(parquet_file):\n",
    "        logger.warning(f\"Parquet introuvable: {parquet_file}\")\n",
    "        return False\n",
    "\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "\n",
    "    price_columns = [c for c in df.columns if c not in ['ID', 'Nom', 'Symbole']]\n",
    "    price_columns = [c for c in price_columns if not pd.isna(pd.to_datetime(c, errors='coerce'))]\n",
    "    price_columns.sort(key=lambda x: pd.to_datetime(x))\n",
    "\n",
    "    if len(price_columns) < 2:\n",
    "        logger.info(\"Pas enough timestamps to calculate variations (>= 2 needed).\")\n",
    "        return False\n",
    "\n",
    "    if df.empty:\n",
    "        logger.info(\"No tokens to include in the report.\")\n",
    "        return False\n",
    "\n",
    "    df_report = df[['ID', 'Nom', 'Symbole']].copy()\n",
    "    first_price_col = price_columns[0]\n",
    "    last_price_col = price_columns[-1]\n",
    "    for i in range(1, len(price_columns)):\n",
    "        current_col = price_columns[i]\n",
    "        pct_change = ((df[current_col] - df[first_price_col]) / df[first_price_col]) * 100\n",
    "        df_report[f\"√Ä {current_col}\"] = pct_change\n",
    "\n",
    "    # Filtre sur la derni√®re colonne et tri d√©croissant par % d'augmentation le plus r√©cent\n",
    "    last_col_name = f\"√Ä {last_price_col}\"\n",
    "    # S'assure que la colonne est bien num√©rique pour un tri correct\n",
    "    df_report[last_col_name] = pd.to_numeric(df_report[last_col_name], errors='coerce')\n",
    "    keep_rows = df_report[last_col_name] >= 1\n",
    "    df_report_filtered = (\n",
    "        df_report[keep_rows]\n",
    "        .sort_values(by=last_col_name, ascending=False, na_position='last')\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_excel_file), exist_ok=True)\n",
    "    df_report_filtered.to_excel(output_excel_file, index=False)\n",
    "    logger.info(f\"Excel written: {output_excel_file} (rows={len(df_report_filtered)})\")\n",
    "    return True\n",
    "\n",
    "# --- Main loop ---\n",
    "while True:\n",
    "    print(\"üì• Collecting data...\")\n",
    "    parquet_path = collect_data()\n",
    "    print(f\"Expected parquet: {parquet_path} -> exists={os.path.exists(parquet_path)}\")\n",
    "\n",
    "    print(\"üìä Generating report...\")\n",
    "    report_ok = generate_performance_report(parquet_path, REPORT_FILE)\n",
    "    if report_ok:\n",
    "        print(f\"‚úÖ Report updated: {REPORT_FILE}\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è Report not generated (conditions not met).\")\n",
    "\n",
    "    print(\"‚è≥ Pausing for 10 minutes...\")\n",
    "    time.sleep(600)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNXEQxwzkASmTEfTLXUCnzH",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
